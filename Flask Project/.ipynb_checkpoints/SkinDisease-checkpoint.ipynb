{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1622c293-d32b-45ca-9487-b91d8883d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Activation, Dropout, Conv2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.applications.mobilenet\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c46ee35e-806e-4bfe-a79e-58462c1a015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SAVE_PATH = r'D:\\Project\\train' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c630d53-a227-4f35-b54d-98e35eb72068",
   "metadata": {},
   "outputs": [],
   "source": [
    "Str_to_Int = {\n",
    "    'Actinic keratosis': 0,\n",
    "    'Atopic Dermatitis': 1,\n",
    "    'Benign keratosis': 2,\n",
    "    'Dermatofibroma': 3,\n",
    "    'Melanocytic nevus': 4,\n",
    "    'Melanoma':5,\n",
    "    'Squamous cell carcinoma': 6,\n",
    "    'Tinea Ringworm Candidiasis':7,\n",
    "    'Vascular lesion': 8\n",
    "}\n",
    "\n",
    "NUM_CLASSES = 9\n",
    "\n",
    "\n",
    "def str_to_Int_mapper(val):\n",
    "    return Str_to_Int[val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440af72c-2692-44c4-b066-9f17961c5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image  \n",
    "\n",
    "\n",
    "dataset = []\n",
    "for directory in os.listdir(IMG_SAVE_PATH):\n",
    "    path = os.path.join(IMG_SAVE_PATH, directory)\n",
    "    for image in os.listdir(path):\n",
    "        new_path = os.path.join(path, image)\n",
    "        try:\n",
    "            imgpath = Image.open(new_path)\n",
    "            imgpath = imgpath.convert('RGB')  # Ensure it's 3-channel\n",
    "            imgpath = imgpath.resize((240, 240))  # PIL resizing\n",
    "            img = np.asarray(imgpath) / 255.0     # Normalize\n",
    "            dataset.append([img, directory])\n",
    "        except FileNotFoundError:\n",
    "            print('Image file not found. Skipping...')\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {new_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578100e7-9780-4f28-910b-d061b737bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    data, labels = zip(*dataset)\n",
    "    temp = list(map(str_to_Int_mapper, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25ffb15a-abf0-4091-b903-675eaaf569b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "labels = to_categorical(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1437bd2-c393-448a-85c2-6f731eee1b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in data:\n",
    "    if i.shape!=(240, 240, 3):\n",
    "        count=count+1\n",
    "print(count)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ff79b-907d-444a-8797-fc8a8153aca8",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "069a8521-9c37-4c80-9afc-f3090319b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "densenet = DenseNet121(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(240,240,3)\n",
    ")\n",
    "\n",
    "def build_densenet():\n",
    "    model = Sequential()\n",
    "    model.add(densenet)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(9, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=Adam(learning_rate=0.00005),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18bf4cbe-6fc4-4d1b-ade7-f7060391c9ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ densenet121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,225</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ densenet121 (\u001b[38;5;33mFunctional\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)          │       \u001b[38;5;34m7,037,504\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   │           \u001b[38;5;34m9,225\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,046,729</span> (26.88 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,046,729\u001b[0m (26.88 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,963,081</span> (26.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,963,081\u001b[0m (26.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">83,648</span> (326.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m83,648\u001b[0m (326.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_densenet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b47bb9a-1160-428a-aae5-18d55d8e4e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 23s/step - accuracy: 0.1905 - loss: 2.7695 - val_accuracy: 0.0714 - val_loss: 2.2995\n",
      "Epoch 2/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 24s/step - accuracy: 0.5557 - loss: 1.3802 - val_accuracy: 0.0429 - val_loss: 2.4453\n",
      "Epoch 3/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m751s\u001b[0m 41s/step - accuracy: 0.6800 - loss: 0.9218 - val_accuracy: 0.0429 - val_loss: 2.7178\n",
      "Epoch 4/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m547s\u001b[0m 29s/step - accuracy: 0.8231 - loss: 0.5549 - val_accuracy: 0.0286 - val_loss: 2.9543\n",
      "Epoch 5/5\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 29s/step - accuracy: 0.8560 - loss: 0.4444 - val_accuracy: 0.0286 - val_loss: 3.0698\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(np.array(data), np.array(labels), epochs = 5, shuffle = True, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c84a1ae1-1066-4424-886d-0d58ea4c66ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"myskin.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eebe8677-b49f-4587-915d-d5ec790f3fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = load_model(\"myskin.h5\")\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=Adam(learning_rate=0.00005),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d789e8b5-bcb1-42cf-a9de-41d9f1264223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "    \n",
    "def plot_acc(history):\n",
    "    sns.set()\n",
    "\n",
    "    fig = pyplot.figure(0, (12, 4))\n",
    "\n",
    "    ax = pyplot.subplot(1, 2, 1)\n",
    "    sns.lineplot(x=history.epoch, y=history.history['accuracy'], label='train')\n",
    "    sns.lineplot(x=history.epoch, y=history.history['val_accuracy'], label='valid')\n",
    "    pyplot.title('Accuracy')\n",
    "    pyplot.tight_layout()\n",
    "\n",
    "    ax = pyplot.subplot(1, 2, 2)\n",
    "    sns.lineplot(x=history.epoch, y=history.history['loss'], label='train')\n",
    "    sns.lineplot(x=history.epoch, y=history.history['val_loss'], label='valid')\n",
    "    pyplot.title('Loss')\n",
    "    pyplot.tight_layout()\n",
    "\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8c7763c-4e7c-4559-af3b-b62f0c462eb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 2. Load images and labels into lists\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     14\u001b[0m     class_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dataset_dir, class_name)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(class_path):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'dataset'"
     ]
    }
   ],
   "source": [
    "#after restarting notebook this loads the necessary data\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 1. Define dataset path and empty lists\n",
    "dataset_dir = \"dataset\"\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# 2. Load images and labels into lists\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_path = os.path.join(dataset_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = load_img(img_path, target_size=(240, 240))\n",
    "            img_array = img_to_array(img)\n",
    "            data.append(img_array)\n",
    "            labels.append(class_name)\n",
    "\n",
    "# 3. Convert lists to numpy arrays\n",
    "data = np.array(data, dtype=np.float32)\n",
    "\n",
    "# 4. Encode labels to numbers and one-hot encode\n",
    "le = LabelEncoder()\n",
    "labels_num = le.fit_transform(labels)\n",
    "labels_cat = to_categorical(labels_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93bf1aac-3392-4826-8f93-9454ae417f2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m plot_acc(history)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_slicing.py:490\u001b[0m, in \u001b[0;36mtrain_validation_split\u001b[1;34m(arrays, validation_split)\u001b[0m\n\u001b[0;32m    487\u001b[0m split_at \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mfloor(batch_dim \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m validation_split)))\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split_at \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m split_at \u001b[38;5;241m==\u001b[39m batch_dim:\n\u001b[1;32m--> 490\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    491\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples, which is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    492\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msufficient to split it into a validation and training set as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    493\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecified by `validation_split=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_split\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovide more data, or a different value for the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_split` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    496\u001b[0m     )\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split\u001b[39m(t, start, end):\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Training data contains 0 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument."
     ]
    }
   ],
   "source": [
    "history = model.fit(np.array(data, dtype=np.float32), np.array(labels), epochs=5, shuffle=True, validation_split=0.2)\n",
    "plot_acc(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c891f8a9-22af-4d9b-95f1-3d9a50c8082a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
