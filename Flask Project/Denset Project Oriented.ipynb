{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0yJKEtdmSTo",
        "outputId": "441742c1-306d-4de3-a142-1fe9f88e0aa1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "qtYaTfpimUqX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "KfOPPLFlmXjz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VYviUo_zHdum"
      },
      "outputs": [],
      "source": [
        "# === Data Paths ===\n",
        "train_dir = '/content/drive/MyDrive/train'\n",
        "val_dir = '/content/drive/MyDrive/val'\n",
        "test_dir = '/content/drive/MyDrive/val'\n",
        "img_size = (224, 224)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpqvM-UWQofa",
        "outputId": "9f3eaebd-9d65-49a5-8920-d338f561882b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 697 images belonging to 9 classes.\n",
            "Found 181 images belonging to 9 classes.\n",
            "Found 181 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "# === Data Augmentation (same as original) ===\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "num_classes = len(train_gen.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aZShzWxnQsig"
      },
      "outputs": [],
      "source": [
        "# === Manual Class Weights (balanced) in TensorFlow ===\n",
        "# Equivalent to sklearn.utils.class_weight.compute_class_weight('balanced', ...)\n",
        "def compute_balanced_class_weights_tf(labels, num_classes: int):\n",
        "    # labels is a NumPy array from Keras generator; convert to tf\n",
        "    y = tf.convert_to_tensor(labels, dtype=tf.int32)\n",
        "    counts = tf.math.bincount(y, minlength=num_classes, maxlength=num_classes)\n",
        "    n_samples = tf.cast(tf.size(y), tf.float32)\n",
        "    n_classes = tf.cast(num_classes, tf.float32)\n",
        "    counts_f = tf.cast(counts, tf.float32)\n",
        "    # avoided div-by-zero\n",
        "    counts_safe = tf.where(counts_f > 0.0, counts_f, tf.ones_like(counts_f))\n",
        "    weights = n_samples / (n_classes * counts_safe)\n",
        "    weights_list = weights.numpy().tolist()  # convert to Python floats\n",
        "    return {i: float(w) for i, w in enumerate(weights_list)}\n",
        "\n",
        "labels = train_gen.classes  # integer labels\n",
        "class_weights = compute_balanced_class_weights_tf(labels, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TqKKk-oVQwA3"
      },
      "outputs": [],
      "source": [
        "# === Built Model (same as original) ===\n",
        "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "base_model.trainable = True  # Unfreeze all layers\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "predictions = Dense(train_gen.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h4YqxHJXQyy8"
      },
      "outputs": [],
      "source": [
        "# === Callbacks ===\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.2, min_lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AorGXWeEQ24I",
        "outputId": "c20268ed-f04b-4d11-d56b-7d656f46282c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m726s\u001b[0m 29s/step - accuracy: 0.1962 - loss: 2.6951 - val_accuracy: 0.3812 - val_loss: 1.8784 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 28s/step - accuracy: 0.6207 - loss: 1.1521 - val_accuracy: 0.4862 - val_loss: 1.4983 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 29s/step - accuracy: 0.7104 - loss: 0.7557 - val_accuracy: 0.5304 - val_loss: 1.3255 - learning_rate: 1.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 29s/step - accuracy: 0.8242 - loss: 0.5115 - val_accuracy: 0.6022 - val_loss: 1.1096 - learning_rate: 1.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 28s/step - accuracy: 0.8637 - loss: 0.3749 - val_accuracy: 0.6740 - val_loss: 0.8846 - learning_rate: 1.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 28s/step - accuracy: 0.8839 - loss: 0.3746 - val_accuracy: 0.7127 - val_loss: 0.8614 - learning_rate: 1.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 28s/step - accuracy: 0.8526 - loss: 0.4163 - val_accuracy: 0.7459 - val_loss: 0.7553 - learning_rate: 1.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 28s/step - accuracy: 0.8963 - loss: 0.3059 - val_accuracy: 0.7569 - val_loss: 0.7579 - learning_rate: 1.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 29s/step - accuracy: 0.9431 - loss: 0.2019 - val_accuracy: 0.7901 - val_loss: 0.7237 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m615s\u001b[0m 28s/step - accuracy: 0.9141 - loss: 0.2187 - val_accuracy: 0.8122 - val_loss: 0.6068 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 28s/step - accuracy: 0.9510 - loss: 0.1622 - val_accuracy: 0.7901 - val_loss: 0.7253 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m634s\u001b[0m 29s/step - accuracy: 0.9505 - loss: 0.1397 - val_accuracy: 0.8177 - val_loss: 0.6064 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m629s\u001b[0m 29s/step - accuracy: 0.9582 - loss: 0.1398 - val_accuracy: 0.7901 - val_loss: 0.7482 - learning_rate: 1.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m618s\u001b[0m 28s/step - accuracy: 0.9390 - loss: 0.1716 - val_accuracy: 0.7845 - val_loss: 0.7185 - learning_rate: 1.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 28s/step - accuracy: 0.9660 - loss: 0.1239 - val_accuracy: 0.8177 - val_loss: 0.8063 - learning_rate: 1.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 28s/step - accuracy: 0.9769 - loss: 0.0794 - val_accuracy: 0.8177 - val_loss: 0.7774 - learning_rate: 2.0000e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m611s\u001b[0m 27s/step - accuracy: 0.9768 - loss: 0.0749 - val_accuracy: 0.8232 - val_loss: 0.7277 - learning_rate: 2.0000e-05\n"
          ]
        }
      ],
      "source": [
        "# === Train (same API) ===\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=30,\n",
        "    validation_data=val_gen,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BPoZLxVgQ555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1cb1a55-5246-4dfe-fb08-1a3c12ba60f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 189ms/step - accuracy: 0.7243 - loss: 0.8366\n",
            "Final Test Accuracy: 81.77%\n"
          ]
        }
      ],
      "source": [
        "# === Evaluate (same API) ===\n",
        "loss, acc = model.evaluate(test_gen)\n",
        "print(f\"Final Test Accuracy: {acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b4k7SNWpQ9BW"
      },
      "outputs": [],
      "source": [
        "# === Predictions (TensorFlow ops, no numpy import) ===\n",
        "# model.predict returns a NumPy array under the hood, but we operate with TF tensors after conversion.\n",
        "Y_pred = model.predict(test_gen, steps=test_gen.samples, verbose=0)\n",
        "Y_pred_tf = tf.convert_to_tensor(Y_pred)\n",
        "y_pred = tf.math.argmax(Y_pred_tf, axis=1, output_type=tf.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "goz0LjR9Q_Di"
      },
      "outputs": [],
      "source": [
        "# True labels from generator (NumPy array), converted to tf\n",
        "y_true = tf.convert_to_tensor(test_gen.classes, dtype=tf.int32)\n",
        "class_names = list(test_gen.class_indices.keys())\n",
        "num_classes = len(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Cg4vEr8TRBmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d130e24-b469-4b36-fbfc-e54e92483da1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix (rows=true, cols=pred):\n",
            "                                       Actinic keratosis           Atopic Dermatitis            Benign keratosis              Dermatofibroma           Melanocytic nevus                    Melanoma     Squamous cell carcinoma  Tinea Ringworm Candidiasis             Vascular lesion\n",
            "           Actinic keratosis                           7                           0                           0                           3                           0                           0                           9                           1                           0\n",
            "           Atopic Dermatitis                           0                          20                           0                           0                           0                           0                           0                           1                           0\n",
            "            Benign keratosis                           0                           0                          20                           0                           0                           0                           0                           0                           0\n",
            "              Dermatofibroma                           0                           0                           0                          19                           0                           0                           1                           0                           0\n",
            "           Melanocytic nevus                           0                           0                           0                           0                          17                           2                           1                           0                           0\n",
            "                    Melanoma                           0                           0                           1                           3                           5                           9                           2                           0                           0\n",
            "     Squamous cell carcinoma                           1                           0                           0                           0                           0                           1                          18                           0                           0\n",
            "  Tinea Ringworm Candidiasis                           0                           1                           0                           0                           0                           0                           0                          19                           0\n",
            "             Vascular lesion                           0                           0                           0                           1                           0                           0                           0                           0                          19\n"
          ]
        }
      ],
      "source": [
        "# === Confusion Matrix (TensorFlow) ===\n",
        "cm_tf = tf.math.confusion_matrix(y_true, y_pred, num_classes=num_classes, dtype=tf.int32)\n",
        "\n",
        "# Pretty-print confusion matrix as text (no plotting libs)\n",
        "def print_confusion_matrix(cm_tensor: tf.Tensor, class_names):\n",
        "    cm = cm_tensor.numpy()  # to print cleanly\n",
        "    k = cm.shape[0]\n",
        "    width = max(5, max(len(c) for c in class_names) + 2)\n",
        "    header = \" \" * width + \"\".join([f\"{c:>{width}}\" for c in class_names])\n",
        "    print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
        "    print(header)\n",
        "    for i in range(k):\n",
        "        row = f\"{class_names[i]:>{width}}\" + \"\".join([f\"{int(cm[i, j]):>{width}d}\" for j in range(k)])\n",
        "        print(row)\n",
        "\n",
        "print_confusion_matrix(cm_tf, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PqH92pJxRHB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b71a7b-e434-4dd1-b04f-6e4466f010c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "Class                  Precision      Recall    F1-Score   Support\n",
            "------------------------------------------------------------------\n",
            "Actinic keratosis         0.8750      0.3500      0.5000        20\n",
            "Atopic Dermatitis         0.9524      0.9524      0.9524        21\n",
            "Benign keratosis          0.9524      1.0000      0.9756        20\n",
            "Dermatofibroma            0.7308      0.9500      0.8261        20\n",
            "Melanocytic nevus         0.7727      0.8500      0.8095        20\n",
            "Melanoma                  0.7500      0.4500      0.5625        20\n",
            "Squamous cell carcinoma      0.5806      0.9000      0.7059        20\n",
            "Tinea Ringworm Candidiasis      0.9048      0.9500      0.9268        20\n",
            "Vascular lesion           1.0000      0.9500      0.9744        20\n",
            "\n",
            "Accuracy                                          0.8177       181\n",
            "Macro avg                 0.8354      0.8169      0.8037       181\n",
            "Weighted avg              0.8361      0.8177      0.8045       181\n"
          ]
        }
      ],
      "source": [
        "# === Classification Report (TensorFlow) ===\n",
        "def classification_report_tf(y_true_tf: tf.Tensor, y_pred_tf: tf.Tensor, class_names):\n",
        "    num_classes = len(class_names)\n",
        "    cm = tf.math.confusion_matrix(y_true_tf, y_pred_tf, num_classes=num_classes, dtype=tf.int32)\n",
        "    tp = tf.linalg.diag_part(cm)\n",
        "    pred_sum = tf.reduce_sum(cm, axis=0)  # predicted positives per class\n",
        "    true_sum = tf.reduce_sum(cm, axis=1)  # actual positives per class\n",
        "\n",
        "    tp_f = tf.cast(tp, tf.float32)\n",
        "    pred_sum_f = tf.cast(pred_sum, tf.float32)\n",
        "    true_sum_f = tf.cast(true_sum, tf.float32)\n",
        "\n",
        "    precision = tf.where(pred_sum_f > 0, tp_f / pred_sum_f, tf.zeros_like(pred_sum_f))\n",
        "    recall = tf.where(true_sum_f > 0, tp_f / true_sum_f, tf.zeros_like(true_sum_f))\n",
        "    denom = precision + recall\n",
        "    f1 = tf.where(denom > 0, 2.0 * precision * recall / denom, tf.zeros_like(denom))\n",
        "\n",
        "    support = true_sum\n",
        "    total = tf.reduce_sum(true_sum)\n",
        "    accuracy = tf.cast(tf.reduce_sum(tp), tf.float32) / tf.cast(total, tf.float32)\n",
        "\n",
        "    macro_p = tf.reduce_mean(precision)\n",
        "    macro_r = tf.reduce_mean(recall)\n",
        "    macro_f1 = tf.reduce_mean(f1)\n",
        "    weights = tf.where(total > 0, tf.cast(support, tf.float32) / tf.cast(total, tf.float32), tf.zeros_like(tf.cast(support, tf.float32)))\n",
        "    weighted_p = tf.reduce_sum(weights * precision)\n",
        "    weighted_r = tf.reduce_sum(weights * recall)\n",
        "    weighted_f1 = tf.reduce_sum(weights * f1)\n",
        "\n",
        "    # Printed nicely\n",
        "    header = f\"{'Class':<20}{'Precision':>12}{'Recall':>12}{'F1-Score':>12}{'Support':>10}\"\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(header)\n",
        "    print(\"-\" * len(header))\n",
        "    prec_np = precision.numpy()\n",
        "    rec_np = recall.numpy()\n",
        "    f1_np = f1.numpy()\n",
        "    sup_np = support.numpy()\n",
        "    for i, name in enumerate(class_names):\n",
        "        print(f\"{name:<20}{prec_np[i]:>12.4f}{rec_np[i]:>12.4f}{f1_np[i]:>12.4f}{int(sup_np[i]):>10d}\")\n",
        "    print(\"\")\n",
        "    print(f\"{'Accuracy':<20}{'':>12}{'':>12}{accuracy.numpy():>12.4f}{int(total.numpy()):>10d}\")\n",
        "    print(f\"{'Macro avg':<20}{macro_p.numpy():>12.4f}{macro_r.numpy():>12.4f}{macro_f1.numpy():>12.4f}{int(total.numpy()):>10d}\")\n",
        "    print(f\"{'Weighted avg':<20}{weighted_p.numpy():>12.4f}{weighted_r.numpy():>12.4f}{weighted_f1.numpy():>12.4f}{int(total.numpy()):>10d}\")\n",
        "\n",
        "classification_report_tf(y_true, y_pred, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "U_plPdCkHoGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e3dcb7-667a-484c-ab18-eb13b1f4178f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model saved to /content/drive/MyDrive/final_project/DenseNet_No_Library_Possible.h5\n"
          ]
        }
      ],
      "source": [
        "# === Save Model ===\n",
        "os.makedirs('/content/drive/MyDrive/final_project', exist_ok=True)\n",
        "save_path = '/content/drive/MyDrive/final_project/DenseNet_No_Library_Possible.h5'\n",
        "model.save(save_path)\n",
        "print(f\"\\nModel saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_pGJhwZZRMEh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}